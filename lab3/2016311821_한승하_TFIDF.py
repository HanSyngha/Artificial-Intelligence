# -*- coding: utf-8 -*-
"""2016311821_한승하_TFIDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dGomJX85spp6NeJj7L-MiObU4Fjohe6e
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
import json
import sys
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

fd = open("2016311821_한승하_TFIDF.txt","w")
sys.stdout = fd

from nltk.tokenize import word_tokenize
with open('./bbc_articles.json') as json_file:
    data = json.load(json_file)
    json_string = data["business"]
    json_tech = data["tech"]
    json_politics = data["politics"]
json_list = list()
for items in json_string:
  json_list.append(items)
for items in json_tech:
  json_list.append(items)
for items in json_politics:
  json_list.append(items)

POS_corpus = list()

for sentence in json_list:
  pos_token = nltk.pos_tag(word_tokenize(sentence))
  POS_corpus.append(' '.join(t[0] for t in pos_token if t[1] in ['NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ']))


tfidfvect = TfidfVectorizer()
tfidfvect.fit_transform(POS_corpus)
print_list = tfidfvect.transform(POS_corpus).toarray().tolist()
fd.seek(0)

for idx in range(0,100):
    print_string = "(bisness%d)" %(idx+1)
    print(print_string)
    for list_items in print_list[idx]:
      print(list_items,end='\t')
    print("\n")
for idx in range(100,200):
    print_string = "\n(tech%d)" %(idx-99)
    print(print_string)
    for list_items in print_list[idx]:
      print(list_items,end='\t')
    print("\n")
for idx in range(200,300):
    print_string = "\n(politics%d)" %(idx-199)
    print(print_string)
    for list_items in print_list[idx]:
      print(list_items,end='\t')  
    print("\n")